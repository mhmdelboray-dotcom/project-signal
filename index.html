<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>Audio Signal Processor - Professional</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Tailwind CSS for modern styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'primary': '#06b6d4', // Sky Blue 500
                        'secondary': '#f97316', // Orange 500
                    }
                }
            }
        }
    </script>
    <!-- Tone.js for audio processing -->
    <script src="https://unpkg.com/tone@next/build/Tone.js"></script>

    <style>
        /* Custom styles for ranges and canvas */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6;
            color: #1f2937;
        }
        .container {
            max-width: 1000px;
            margin: 0 auto;
        }
        canvas {
            background-color: #1f2937;
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        /* Custom styles for range input */
        input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #06b6d4;
            cursor: pointer;
            box-shadow: 0 0 5px rgba(0,0,0,0.3);
        }
    </style>
</head>
<body class="p-4 md:p-8">
    <header class="text-center mb-8 bg-white p-6 rounded-xl shadow-lg">
        <h1 class="text-3xl font-extrabold text-primary">Audio Signal Processor</h1>
        <p class="text-gray-600 mt-2 text-sm md:text-base">
          
 ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉŸÖ ŸÅŸä ŸÖŸÜÿµÿßÿ™ŸÜÿß ŸÖÿπŸÉŸÖ ÿßŸÑŸÖŸáŸÜÿØÿ≥ ŸÖÿµÿ∑ŸÅŸä ÿßŸÑÿ®ÿ±ÿπŸä 
        </p>
    </header>

    <main class="container space-y-8">
        
        <!-- File Input and Controls -->
        <div class="bg-white p-6 rounded-xl shadow-lg border border-gray-200">
            <input id="file" type="file" accept="audio/*" class="w-full text-gray-700 mb-6 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-primary file:text-white hover:file:bg-cyan-600"/>
            
            <div id="controls-panel" class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-6">
                <!-- Filter Type -->
                <div class="control flex flex-col space-y-2">
                    <label for="filterType" class="text-sm font-medium text-gray-700">Filter</label>
                    <select id="filterType" class="p-2 border border-gray-300 rounded-lg focus:ring-primary focus:border-primary">
                        <option value="none">None</option>
                        <option value="lowpass">Low-pass</option>
                        <option value="highpass">High-pass</option>
                    </select>
                </div>

                <!-- Cutoff Frequency -->
                <div class="control flex flex-col space-y-2">
                    <label for="cutoff" class="text-sm font-medium text-gray-700 flex justify-between">
                        Cutoff (Hz)
                        <span id="cutoffVal" class="font-bold text-primary">3000</span>
                    </label>
                    <input id="cutoff" type="range" min="100" max="12000" value="3000" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
                </div>

                <!-- Speed (Time Stretch) -->
                <div class="control flex flex-col space-y-2">
                    <label for="speed" class="text-sm font-medium text-gray-700 flex justify-between">
                        Speed (time stretch)
                        <span id="speedVal" class="font-bold text-primary">1.00</span>
                    </label>
                    <input id="speed" type="range" min="0.5" max="2" step="0.01" value="1" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
                </div>

                <!-- Pitch Shift (Semitones) -->
                <div class="control flex flex-col space-y-2">
                    <label for="pitch" class="text-sm font-medium text-gray-700 flex justify-between">
                        Pitch (semitones)
                        <span id="pitchVal" class="font-bold text-primary">0</span>
                    </label>
                    <input id="pitch" type="range" min="-12" max="12" step="1" value="0" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
                </div>
            </div>
        </div>
        
        <!-- Playback and Export Buttons -->
        <div class="buttons flex flex-wrap justify-center gap-4">
            <button id="play" class="btn bg-primary text-white py-3 px-8 rounded-full font-semibold shadow-lg hover:bg-cyan-600 transition duration-150 disabled:bg-gray-400" disabled>
                ‚ñ∂ Play
            </button>
            <button id="stop" class="btn bg-secondary text-white py-3 px-8 rounded-full font-semibold shadow-lg hover:bg-orange-600 transition duration-150 disabled:bg-gray-400" disabled>
                ‚ñ† Stop
            </button>
            <button id="export" class="btn bg-gray-600 text-white py-3 px-8 rounded-full font-semibold shadow-lg hover:bg-gray-700 transition duration-150 disabled:bg-gray-400" disabled>
                ‚¨áÔ∏è Export Processed (WAV)
            </button>
        </div>
        
        <!-- Waveform Canvas -->
        <canvas id="wave" width="800" height="150" class="w-full max-w-full"></canvas>

        <footer class="text-center pt-4 text-gray-500">
            <small>By ENG/Mostafa Elboray.</small>
        </footer>
    </main>

    <script>
        // app.js - The complete JavaScript logic

        let player, pitchShift, filter, analyser;
        let fileBuffer = null;
        let isPlaying = false;

        const fileInput = document.getElementById('file');
        const filterType = document.getElementById('filterType');
        const cutoff = document.getElementById('cutoff');
        const cutoffVal = document.getElementById('cutoffVal');
        const speed = document.getElementById('speed');
        const speedVal = document.getElementById('speedVal');
        const pitch = document.getElementById('pitch');
        const pitchVal = document.getElementById('pitchVal');
        const playBtn = document.getElementById('play');
        const stopBtn = document.getElementById('stop');
        const exportBtn = document.getElementById('export');

        const canvas = document.getElementById('wave');
        const ctx = canvas.getContext('2d');
        
        // Initial UI values
        cutoffVal.textContent = cutoff.value;
        speedVal.textContent = parseFloat(speed.value).toFixed(2);
        pitchVal.textContent = pitch.value;

        // Helper function to reset buttons
        function setControlState(disabled) {
            playBtn.disabled = disabled;
            stopBtn.disabled = disabled;
            exportBtn.disabled = disabled;
            playBtn.textContent = '‚ñ∂ Play';
        }

        // --- Event Listeners for Dynamic Control Updates ---

        // Cutoff Frequency
        cutoff.addEventListener('input', (e) => {
            const value = parseFloat(e.target.value);
            cutoffVal.textContent = value;
            if (filter) filter.frequency.value = value;
        });

        // Pitch Shift
        pitch.addEventListener('input', (e) => {
            const value = parseInt(e.target.value, 10);
            pitchVal.textContent = value;
            if (pitchShift) pitchShift.pitch = value;
        });
        
        // Speed (Crucial for dynamic update during playback)
        speed.addEventListener('input', (e) => {
            const newSpeed = parseFloat(e.target.value);
            speedVal.textContent = newSpeed.toFixed(2);
            
            // Update the player's speed immediately if it exists
            if(player && player.buffer) {
                player.playbackRate = newSpeed;
            }
        });

        // Filter Type Change
        filterType.addEventListener('change', (e) => {
            if (player && filter && pitchShift) {
                const type = e.target.value;
                if (type === 'none') {
                    // Bypass filter
                    pitchShift.disconnect(filter);
                    pitchShift.connect(analyser); 
                } else {
                    // Engage filter
                    pitchShift.disconnect(analyser);
                    pitchShift.connect(filter);
                    filter.type = type;
                }
            }
        });


        // --- File Loading Logic (Faster with ArrayBuffer) ---

        fileInput.addEventListener('change', async (e)=>{
            const f = e.target.files[0];
            if(!f) return;
            
            setControlState(true);
            playBtn.textContent = '‚åõ Loading...';

            try {
                // 1. Read file as ArrayBuffer
                const array = await f.arrayBuffer();
                
                // 2. Decode Audio Data via WebAudio Context
                const audioBuf = await Tone.getContext().rawContext.decodeAudioData(array);
                fileBuffer = audioBuf;

                // 3. Dispose old player/nodes
                if(player) player.dispose();
                if(pitchShift) pitchShift.dispose();
                if(filter) filter.dispose();
                if(analyser) analyser.dispose();

                // 4. Create new Player with the decoded buffer
                player = new Tone.Player({
                    url: audioBuf,
                    autostart: false,
                    loop: true, // Use loop for continuous playback during adjustments
                });
                
                // 5. Setup audio graph and connect nodes
                setupNodes();
                
                // 6. Final setup
                setControlState(false);
                console.log('File loaded, duration:', fileBuffer.duration);
                // Draw initial waveform
                drawWaveformStatic(fileBuffer);

            } catch (error) {
                console.error("Error loading or decoding audio:", error);
                alert("Failed to load audio file: " + error.message);
                setControlState(true);
            }
        });
        
        // --- Setup Audio Graph ---
        
        function setupNodes(){
            // Create New Nodes
            pitchShift = new Tone.PitchShift(parseInt(pitch.value, 10));
            filter = new Tone.Filter({
                type: filterType.value === 'none' ? 'lowpass' : filterType.value,
                frequency: parseFloat(cutoff.value),
                rolloff: -12
            });
            analyser = new Tone.Analyser('waveform', 1024);

            // Connect Player -> PitchShift -> Filter -> Analyser -> Destination
            player.connect(pitchShift);
            
            // Initial connection bypasses or uses the filter based on selection
            if(filterType.value === 'none') {
                 pitchShift.connect(analyser); // Connect PitchShift directly to Analyser
            } else {
                 pitchShift.connect(filter);
                 filter.connect(analyser); // Connect Filter to Analyser
            }
            
            analyser.toDestination(); // Analyser output goes to master
            
            // Apply current speed value
            player.playbackRate = parseFloat(speed.value);
        }

        // --- Waveform Visualization ---
        
        // Function to draw the waveform when static (not playing)
        function drawWaveformStatic(buffer) {
            if (!buffer) return;
            // Get channel data (assuming mono or first channel)
            const data = buffer.getChannelData(0);
            const width = canvas.width;
            const height = canvas.height;
            const step = Math.ceil(data.length / width);
            const amp = height / 2;
            
            ctx.clearRect(0, 0, width, height); // Clear screen
            ctx.fillStyle = '#1f2937';
            ctx.fillRect(0, 0, width, height);

            ctx.beginPath();
            ctx.strokeStyle = '#06b6d4';
            ctx.lineWidth = 2;
            
            // Draw amplitude envelope
            for (let i = 0; i < width; i++) {
                let min = 1.0;
                let max = -1.0;
                
                for (let j = 0; j < step; j++) {
                    const datum = data[(i * step) + j];
                    if (datum < min) min = datum;
                    if (datum > max) max = datum;
                }
                
                const yMin = (1 + min) * amp;
                const yMax = (1 + max) * amp;

                // Draw vertical line from min to max
                ctx.moveTo(i, yMin);
                ctx.lineTo(i, yMax);
            }
            ctx.stroke();
        }


        // Function to draw the real-time waveform (FFT) and playback indicator
        function draw(){
            requestAnimationFrame(draw);
            
            // Draw real-time FFT if playing, otherwise draw the static buffer
            if(analyser && isPlaying){
                // Draw real-time waveform from analyser
                const waveform = analyser.getValue();
                ctx.fillStyle = '#1f2937';
                ctx.fillRect(0,0,canvas.width,canvas.height);
                ctx.lineWidth = 2;
                ctx.strokeStyle = '#06b6d4';
                ctx.beginPath();
                const slice = canvas.width / waveform.length;
                for(let i=0;i<waveform.length;i++){
                    const v = (waveform[i] + 1) / 2; // normalize -1..1 to 0..1
                    const y = v * canvas.height;
                    if(i===0) ctx.moveTo(0,y);
                    else ctx.lineTo(i*slice, y);
                }
                ctx.stroke();
                
                // Draw Playhead
                const duration = player.buffer.duration;
                // player.currentTime returns the time in seconds relative to when it was started
                const currentPlaybackTime = player.currentTime % duration; 
                const progress = (currentPlaybackTime / duration) * canvas.width;
                
                ctx.fillStyle = 'red';
                ctx.fillRect(progress, 0, 2, canvas.height);
            } else if (fileBuffer) {
                // If not playing, ensure the static waveform is drawn
                drawWaveformStatic(fileBuffer);
            } else {
                // Clear canvas if no file is loaded
                ctx.fillStyle = '#1f2937';
                ctx.fillRect(0,0,canvas.width,canvas.height);
                ctx.fillStyle = '#9ca3af';
                ctx.font = '20px Inter';
                ctx.textAlign = 'center';
                ctx.fillText('Upload an audio file to view the waveform', canvas.width / 2, canvas.height / 2);
            }
        }
        draw(); // Start the animation loop

        // --- Play & Stop Logic ---
        
        playBtn.addEventListener('click', async ()=>{
            if(!player || !fileBuffer) { alert('Upload audio file first'); return; }
            
            // Resume context if suspended (needed for first user interaction)
            if(!Tone.context.state || Tone.context.state === 'suspended') {
                await Tone.start();
            }
            
            if(isPlaying) {
                // Pause logic: Stop and reset the starting time for the next play
                player.stop(); 
                isPlaying = false;
                playBtn.textContent = '‚ñ∂ Play';
                stopBtn.disabled = true;
                return;
            }
            
            // Start playback
            player.start(Tone.now(), 0); 
            isPlaying = true;
            playBtn.textContent = '‚è∏ Pause';
            stopBtn.disabled = false;
        });

        stopBtn.addEventListener('click', ()=> {
            if(player && isPlaying){
                player.stop();
                isPlaying = false;
                playBtn.textContent = '‚ñ∂ Play';
                stopBtn.disabled = true;
            }
        });

        // --- Export Logic (Offline Rendering) ---
        
        exportBtn.addEventListener('click', async ()=>{
            if(!fileBuffer){ alert('Upload audio file first'); return; }
            if(isPlaying) { player.stop(); isPlaying = false; }
            
            exportBtn.disabled = true;
            exportBtn.textContent = 'üíæ Rendering...';

            try {
                // Tone.Offline is generally better than raw WebAudio for complex Tone effects (like PitchShift)
                
                // Capture current parameters
                const currentSpeed = parseFloat(speed.value) || 1.0;
                const currentPitch = parseInt(pitch.value, 10) || 0;
                const currentCutoff = parseFloat(cutoff.value);
                const currentFilterType = filterType.value;
                const duration = fileBuffer.duration / currentSpeed; // Adjusted duration for speed change

                // Render the entire Tone graph offline
                const renderedBuffer = await Tone.Offline(({ transport }) => {
                    const offlinePlayer = new Tone.Player(fileBuffer).toDestination();
                    
                    const offlinePitchShift = new Tone.PitchShift(currentPitch);
                    const offlineFilter = new Tone.Filter({
                        type: currentFilterType === 'none' ? 'lowpass' : currentFilterType,
                        frequency: currentCutoff,
                        rolloff: -12
                    });
                    
                    // Connect nodes for offline rendering
                    if (currentFilterType === 'none') {
                        offlinePlayer.connect(offlinePitchShift);
                        offlinePitchShift.toDestination();
                    } else {
                        offlinePlayer.connect(offlinePitchShift);
                        offlinePitchShift.connect(offlineFilter);
                        offlineFilter.toDestination();
                    }
                    
                    // Apply speed to the player
                    offlinePlayer.playbackRate = currentSpeed;
                    
                    // Schedule playback for the full duration
                    offlinePlayer.start(0);
                    transport.stop(duration);
                }, duration); // Render for the new calculated duration

                // Convert AudioBuffer to WAV
                const wav = audioBufferToWav(renderedBuffer);
                const blob = new Blob([new DataView(wav)], {type: 'audio/wav'});
                const url = URL.createObjectURL(blob);
                
                // Trigger download
                const a = document.createElement('a');
                a.href = url;
                a.download = 'processed_audio.wav';
                document.body.appendChild(a);
                a.click();
                
                // Cleanup
                window.URL.revokeObjectURL(url);
                a.remove();
                
                alert('Audio exported successfully!');
                
            } catch (e) {
                console.error("Export Error:", e);
                alert("An error occurred during export. See console for details.");
            } finally {
                exportBtn.disabled = false;
                exportBtn.textContent = '‚¨áÔ∏è Export Processed (WAV)';
            }
        });

        // --- Utility Functions for WAV Encoding (Required for Export) ---

        // utility: convert AudioBuffer to WAV (Float32 -> 16-bit PCM)
        function audioBufferToWav(buffer, opt) {
            opt = opt || {}
            var numChannels = buffer.numberOfChannels
            var sampleRate = buffer.sampleRate
            var format = opt.float32 ? 3 : 1
            var bitDepth = format === 3 ? 32 : 16

            var result
            if (numChannels === 2) {
                result = interleave(buffer.getChannelData(0), buffer.getChannelData(1))
            } else {
                result = buffer.getChannelData(0)
            }

            return encodeWAV(result, format, sampleRate, numChannels, bitDepth)
        }

        function interleave(inputL, inputR){
            var length = inputL.length + inputR.length
            var result = new Float32Array(length)

            var index = 0
            var inputIndex = 0

            while (index < length){
                result[index++] = inputL[inputIndex]
                result[index++] = inputR[inputIndex]
                inputIndex++
            }
            return result
        }

        function encodeWAV(samples, format, sampleRate, numChannels, bitDepth){
            var bytesPerSample = bitDepth / 8
            var blockAlign = numChannels * bytesPerSample

            var buffer = new ArrayBuffer(44 + samples.length * bytesPerSample)
            var view = new DataView(buffer)

            /* RIFF identifier */
            writeString(view, 0, 'RIFF')
            /* file length */
            view.setUint32(4, 36 + samples.length * bytesPerSample, true)
            /* RIFF type */
            writeString(view, 8, 'WAVE')
            /* format chunk identifier */
            writeString(view, 12, 'fmt ')
            /* format chunk length */
            view.setUint32(16, 16, true)
            /* sample format (raw) */
            view.setUint16(20, format, true)
            /* channel count */
            view.setUint16(22, numChannels, true)
            /* sample rate */
            view.setUint32(24, sampleRate, true)
            /* byte rate (sample rate * block align) */
            view.setUint32(28, sampleRate * blockAlign, true)
            /* block align (channel count * bytes per sample) */
            view.setUint16(32, blockAlign, true)
            /* bits per sample */
            view.setUint16(34, bitDepth, true)
            /* data chunk identifier */
            writeString(view, 36, 'data')
            /* data chunk length */
            view.setUint32(40, samples.length * bytesPerSample, true)
            if (format === 1) { // PCM16
                floatTo16BitPCM(view, 44, samples)
            } else {
                writeFloat32(view, 44, samples)
            }

            return buffer
        }

        function floatTo16BitPCM(output, offset, input){
            for (var i = 0; i < input.length; i++, offset+=2){
                var s = Math.max(-1, Math.min(1, input[i]))
                output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true)
            }
        }

        function writeFloat32(output, offset, input){
            for (var i = 0; i < input.length; i++, offset+=4){
                output.setFloat32(offset, input[i], true)
            }
        }

        function writeString(view, offset, string){
            for (var i = 0; i < string.length; i++){
                view.setUint8(offset + i, string.charCodeAt(i))
            }
        }
    </script>
</body>
</html>
